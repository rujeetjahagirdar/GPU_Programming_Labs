#include "scan.h"
#include <cuda_runtime.h>
#include <stdio.h> // for printf


__global__ void Kogge_Stone_scan_kernel(float *X, float *Y, unsigned int N) {
    __shared__ float XY[BLOCK_SIZE];
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;

    // Load data into shared memory with boundary checking
    if (i < N) {
        XY[threadIdx.x] = X[i];
    } else {
        XY[threadIdx.x] = 0;
    }
    // Perform parallel scan (inclusive)
    for (unsigned int stride = 1; stride < blockDim.x; stride *= 2) {
        __syncthreads();
        float temp;
        if(threadIdx.x >= stride)
            temp = XY[threadIdx.x] + XY[threadIdx.x-stride];
        __syncthreads();
        if(threadIdx.x >= stride)
            XY[threadIdx.x] = temp;
    }

    if (i < N) {
        Y[i] = XY[threadIdx.x];
    }
}


void scan(float *input, float *output, int len) {
    float *d_input, *d_output;
    int num_blocks = (len + BLOCK_SIZE - 1) / BLOCK_SIZE;

    // Allocate GPU memory
    cudaMalloc((void**)&d_input, len * sizeof(float));
    cudaMalloc((void**)&d_output, len * sizeof(float));

    // printf("Input array:\n");
    // for (int i = 0; i < len; ++i) {
    //     printf("%.2f ", input[i]);
    // }
    // printf("\n");

    // Copy memory to the GPU
    cudaMemcpy(d_input, input, len * sizeof(float), cudaMemcpyHostToDevice);

    // Initialize the grid and block dimensions
    dim3 blockDim(BLOCK_SIZE, 1, 1);
    dim3 gridDim(num_blocks, 1, 1);

    // Launch the GPU Kernel
    Kogge_Stone_scan_kernel<<<gridDim, blockDim>>>(d_input, d_output, len);
    gpuErrchk(cudaPeekAtLastError());
    gpuErrchk(cudaDeviceSynchronize());

    // Copy the GPU memory back to the CPU
    cudaMemcpy(output, d_output, len * sizeof(float), cudaMemcpyDeviceToHost);
    // printf("Output array:\n");
    // for (int i = 0; i < len; ++i) {
    //     printf("%.2f ", output[i]);
    // }
    // printf("\n");

    // Free the GPU memory
    cudaFree(d_input);
    cudaFree(d_output);
}
